# ğŸ§  AI Research Assistant using LangChain

**Context-Aware Research Assistant using LangChain, ChromaDB, and Flan-T5**

## ğŸ“„ Overview

This project demonstrates how to build a lightweight, local, and modular AI-powered Research Assistant using:
- **LangChain**
- **HuggingFace Pipelines**
- **Chroma Vector Database**
- **Sentence Transformers**
- **Flan-T5-base model**

The assistant is capable of:
- Answering user queries from a document
- Giving simplified explanations
- Summarizing text
- Holding memory-driven conversations

---

## ğŸ¯ Objectives

- Build a modular Research Assistant using four LangChain chains:
  - **Retrieval-based QA**
  - **Simple Explanation**
  - **Text Summarization**
  - **Conversational Memory**
- Use only open-source models (locally hosted) for privacy and reproducibility.
- Showcase performance using the lightweight `flan-t5-base` model.

---

## ğŸ› ï¸ Tech Stack

- Python 3.x
- LangChain
- HuggingFace Transformers
- Sentence-Transformers
- ChromaDB
